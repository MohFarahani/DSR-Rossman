{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49e9a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5b22c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH to Input data\n",
    "PATH_TRAIN = \"data/train.csv\"\n",
    "PATH_TEST = \"data/holdout.csv\"\n",
    "PATH_STORE = \"data/store.csv\"\n",
    "PATH_STORE_MODIFIED = \"data/store_modified.csv\"\n",
    "MODEL_NAME = \"XGBoost.txt\"\n",
    "LABEL_ENCODE=\"LabelEncode\"\n",
    "TARGET_ENCODE=\"TargetEncode\"\n",
    "COLUMNS_NAME = \"Columns_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f3fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMSPE for evaluation\n",
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0af15c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rossman():\n",
    "    \n",
    "    def __init__(self,train_path=None,store_path=None,store_modified_path=None):\n",
    "        \n",
    "        self.train_path = train_path\n",
    "        self.store_path = store_path\n",
    "        self.store_modified_path = store_modified_path\n",
    "        self.train = None\n",
    "        self.train_full = None\n",
    "        self.test_full = None\n",
    "        self.store = None\n",
    "        self.model = None\n",
    "    \n",
    "    \n",
    "    def read_data(self,PATH_TRAIN,PATH_STORE):\n",
    "        \n",
    "        self.train = pd.read_csv(PATH_TRAIN, parse_dates=True, low_memory = False, index_col=None)\n",
    "        self.train['Date'] = pd.to_datetime(self.train[\"Date\"])\n",
    "        self.store = pd.read_csv(PATH_STORE, low_memory=False)\n",
    "        return self.train,self.store\n",
    "                                 \n",
    "    def clean(self,df):\n",
    "        df=df[df['Sales']>0]\n",
    "        if 'StateHoliday' in df.columns:\n",
    "            df.loc[df['StateHoliday']==0,'StateHoliday']='0'\n",
    "            df.loc[df['StateHoliday']=='0','StateHoliday']='0'\n",
    "        return df\n",
    "    \n",
    "                                 \n",
    "    def fillna(self,df,columns_mean,columns_most):\n",
    "                                 \n",
    "        def fillna_mean(df,columns):\n",
    "            for col in columns:\n",
    "                if col in df.columns:\n",
    "                    mean_value = int(df[col].mean())\n",
    "                    df.loc[:,col].fillna(value=mean_value,inplace=True)\n",
    "            return df\n",
    "\n",
    "        def fillna_most(df,columns):\n",
    "            for col in columns:\n",
    "                if col in df.columns:\n",
    "                    most_value = df[col].value_counts().idxmax()\n",
    "                    df.loc[:,col].fillna(value=most_value,inplace=True)\n",
    "            return df\n",
    "        \n",
    "        df = fillna_mean(df,columns_mean)\n",
    "        df = fillna_most(df,columns_most)\n",
    "\n",
    "        return df \n",
    "    \n",
    "                                 \n",
    "    def fillna_train(self,df_train):\n",
    "                                 \n",
    "        columns_mean = ['DayOfWeek','Customers']\n",
    "        columns_most = ['Promo','SchoolHoliday','StateHoliday']\n",
    "        df_train = self.fillna(df_train,columns_mean,columns_most)\n",
    "        return df_train\n",
    "    \n",
    "                                 \n",
    "    def fillna_store(self,df_store):\n",
    "        columns_mean = ['CompetitionOpenSinceMonth',\n",
    "                'CompetitionOpenSinceYear',\n",
    "                'CompetitionDistance',\n",
    "                'Promo2SinceWeek',\n",
    "                'Promo2SinceYear'\n",
    "                 ] \n",
    "        columns_most = ['PromoInterval']\n",
    "        df_store = self.fillna(df_store,columns_mean,columns_most)\n",
    "        return df_store\n",
    "\n",
    "                                 \n",
    "    def merge_train_store(self,train,store):\n",
    "                                 \n",
    "        train_full = train.merge(store, on='Store', how='inner')\n",
    "        return train_full\n",
    "    \n",
    "                                 \n",
    "    def add_features(self,train_full,store,UPDATE=False):\n",
    "        \n",
    "        if UPDATE== False:\n",
    "            if('CustomerPerDay' not in train_full.columns):\n",
    "                cutomer_store = train_full.groupby('Store').agg(cust_st=('Customers','sum'))\n",
    "                open_store = train_full.groupby('Store').agg(open_st=('Open','count'))\n",
    "                customer_day_store = cutomer_store[\"cust_st\"]//open_store['open_st']\n",
    "                temp_df = pd.DataFrame({\"CustomerPerDay\":customer_day_store})\n",
    "                train_full = pd.merge(train_full, temp_df, how='inner', on=['Store'])\n",
    "                store = pd.merge(store, temp_df, how='inner', on=['Store'])\n",
    "        \n",
    "        train_full['CompetitionOpen'] = 12 * (train_full.loc[:,'Date'].dt.year -\n",
    "                                              train_full.CompetitionOpenSinceYear)+\\\n",
    "                                        (train_full.loc[:,'Date'].dt.month -\n",
    "                                         train_full.CompetitionOpenSinceMonth)\n",
    "\n",
    "        # Promo open time in months\n",
    "        train_full['PromoOpen'] = 12 * (train_full.loc[:,'Date'].dt.year - train_full.Promo2SinceYear)+\\\n",
    "                              (train_full.loc[:,'Date'].dt.weekofyear - train_full.Promo2SinceWeek)/ 4.0\n",
    "\n",
    "        train_full['WeekOfYear'] = train_full.loc[:,'Date'].dt.weekofyear\n",
    "\n",
    "        \n",
    "        return train_full,store\n",
    "    \n",
    "    \n",
    "    def encode_choice(self):\n",
    "                                 \n",
    "        encode_dict = {}\n",
    "        encode_dict['OneHot'] = ['StoreType','Assortment','PromoInterval','StateHoliday']\n",
    "        encode_dict['Label'] = []\n",
    "        encode_dict['Freq'] = ['Store'] \n",
    "        encode_dict['Target'] = [] \n",
    "        return encode_dict\n",
    "    \n",
    "                                 \n",
    "    def encoding(self,train_full,TRAIN=True):\n",
    "                                 \n",
    "        encode_dict = self.encode_choice()\n",
    "        for key,value in encode_dict.items():\n",
    "            \n",
    "            if key=='OneHot':\n",
    "                for col in value:\n",
    "                    if col in train_full.columns:\n",
    "                        train_full = pd.get_dummies(train_full, columns = [col])\n",
    "                        \n",
    "            if key=='Label':\n",
    "                if TRAIN==True:\n",
    "                    le= LabelEncoder()\n",
    "                    for col in value:\n",
    "                        if col in train_full.columns: \n",
    "                           le.fit_transform(train_full[col])\n",
    "                           train_full[col] = le.transform(train_full[col]) \n",
    "                    LABEL_FILE = open(LABEL_ENCODE,\"wb\")\n",
    "                    pickle.dump(le,LABEL_FILE)\n",
    "                    LABEL_FILE.close()\n",
    "                elif value !=[]:\n",
    "                    LABEL_FILE = open(LABEL_ENCODE,\"rb\")\n",
    "                    le = pickle.load(LABEL_FILE)\n",
    "                    LABEL_FILE.close()\n",
    "                    for col in value:\n",
    "                        if col in train_full.columns: \n",
    "                           train_full[col] = le.fit(train_full[col])\n",
    "                    \n",
    "                    \n",
    "            elif key=='Freq':\n",
    "                for col in value:\n",
    "                    if col in train_full.columns:\n",
    "                        freq = train_full.groupby(col).size()/len(train_full)\n",
    "                        train_full.loc[:,col+'_freq'] = train_full.loc[:,col].map(freq)\n",
    "            if key=='Target': \n",
    "                if TRAIN==True:\n",
    "                    te= TargetEncoder(cols=value)\n",
    "                    te.fit_transform(train_full,train_full['Sales'])\n",
    "                    TARGET_FILE = open(TARGET_ENCODE,\"wb\")\n",
    "                    pickle.dump(le,TARGET_FILE)\n",
    "                    TARGET_FILE.close()\n",
    "                elif value !=[]:\n",
    "                    print(\"value: \",value)\n",
    "                    TARGET_FILE = open(TARGET_ENCODE,\"rb\")\n",
    "                    te = pickle.load(TARGET_FILE)\n",
    "                    TARGET_FILE.close()\n",
    "                    te.fit(train_full)\n",
    "                \n",
    "        return train_full\n",
    "    \n",
    "                                 \n",
    "    def drop_columns(self,train_full):\n",
    "                                 \n",
    "        columns = ['Store','Customer','Date','Open',\n",
    "                   'CompetitionOpenSinceMonth',\n",
    "                   'CompetitionOpenSinceYear', \n",
    "                   'Promo2SinceYear', 'Promo2SinceWeek']\n",
    "        train_full.drop(columns = columns, inplace=True, errors='ignore')\n",
    "        return train_full\n",
    "                                 \n",
    "    def X_y(self,train_full): \n",
    "                                 \n",
    "        X = train_full.drop(columns=['Sales'])\n",
    "        y = train_full['Sales']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "     \n",
    "                                 \n",
    "    def model_xgb(self, X_train, X_test, y_train, y_test):\n",
    "        def log_target(y_train, y_test):\n",
    "            \"\"\"\n",
    "            Get log of the target as it has a better distribution.\n",
    "            \"\"\"\n",
    "            y_train_log = np.log2(y_train)\n",
    "            y_test_log =  np.log2(y_test)\n",
    "\n",
    "            return y_train_log, y_test_log\n",
    "        \n",
    "        def rmspe(y, yhat):\n",
    "            return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "\n",
    "        def rmspe_xg(yhat, y):\n",
    "            y = np.expm1(y.get_label())\n",
    "            yhat = np.expm1(yhat)\n",
    "            return \"rmspe\", rmspe(y,yhat)       \n",
    "        \n",
    "        y_train, y_test = log_target(y_train, y_test)\n",
    "        params = {\"objective\": \"reg:linear\", # for linear regression\n",
    "          \"booster\" : \"gbtree\",   # use tree based models \n",
    "          \"eta\": 0.03,   # learning rate\n",
    "          \"max_depth\": 10,    # maximum depth of a tree\n",
    "          \"subsample\": 0.9,    # Subsample ratio of the training instances\n",
    "          \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\n",
    "          \"silent\": 1,   # silent mode\n",
    "          \"seed\": 10   # Random number seed\n",
    "          }\n",
    "        num_boost_round = 30\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, y_train)\n",
    "        dvalid = xgb.DMatrix(X_test, y_test)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "        model = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \n",
    "                          early_stopping_rounds= 100, feval=rmspe_xg, verbose_eval=True)\n",
    "        return model\n",
    "        \n",
    "    def xgb_simple(self, X_train, X_test, y_train, y_test):       \n",
    "        model = xgb.XGBRegressor(max_depth=10,n_estimators=200)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        RMSPE = metric(y_predict, y_test.to_numpy())\n",
    "        print(\"RMSPE: \",RMSPE)\n",
    "        return model\n",
    "    \n",
    "    def training(self,train_path,store_path,PATH_STORE_MODIFIED,LOG=True):\n",
    "        train,store = self.read_data(train_path,store_path)\n",
    "        train = self.clean(train)\n",
    "        train = self.fillna_train(train)\n",
    "        store = self.fillna_store(store)\n",
    "        train_full = self.merge_train_store(train,store)\n",
    "        train_full,store = self.add_features(train_full,store)\n",
    "        train_full = self.encoding(train_full)\n",
    "        train_full = self.drop_columns(train_full)\n",
    "        self.train_full = train_full\n",
    "        self.cols = train_full.columns.values.tolist()\n",
    "        with open(COLUMNS_NAME, 'wb') as f:\n",
    "            pickle.dump(self.cols, f)\n",
    "        X_train, X_test, y_train, y_test = self.X_y(train_full)\n",
    "        if LOG == True:\n",
    "            self.model = self.model_xgb(X_train, X_test, y_train, y_test)\n",
    "        else:\n",
    "            self.model = self.xgb_simple(X_train, X_test, y_train, y_test)\n",
    "        store.to_csv(PATH_STORE_MODIFIED,index=False)\n",
    "        self.store_modified_path = PATH_STORE_MODIFIED\n",
    "        self.model.save_model(MODEL_NAME)\n",
    "        \n",
    "        \n",
    "    def testing(self,path_test,PATH_STORE_MODIFIED,LOG =True):\n",
    "        test,store = self.read_data(path_test,self.store_modified_path)\n",
    "        test = self.clean(test)\n",
    "        test = self.fillna_train(test)\n",
    "        test_full = self.merge_train_store(test,store)\n",
    "        test_full,_ = self.add_features(test_full,store,UPDATE=True)\n",
    "        test_full = self.encoding(test_full,TRAIN=False)\n",
    "        test_full = self.drop_columns(test_full)\n",
    "        test_full.dropna()\n",
    "        self.test_full = test_full\n",
    "        with open(COLUMNS_NAME, 'rb') as f:\n",
    "            col_names = pickle.load(f)\n",
    "        test_full = test_full[col_names]\n",
    "        X = test_full.drop(columns=['Sales'])\n",
    "        y = test_full['Sales']\n",
    "        self.model = xgb.XGBRegressor()\n",
    "        self.model.load_model(MODEL_NAME)\n",
    "        y_predict = self.model.predict(X)\n",
    "        if LOG ==True:\n",
    "            RMSPE = metric(np.exp(y_predict), y.to_numpy())\n",
    "        else:\n",
    "            RMSPE = metric(y_predict, y.to_numpy())               \n",
    "        print(\"RMSPE: \",RMSPE)\n",
    "      \n",
    "        \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07c89f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhnaj\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "C:\\Users\\mhnaj\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:98: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:11.76\teval-rmse:11.7616\ttrain-rmspe:0.999994\teval-rmspe:0.999994\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:11.4075\teval-rmse:11.409\ttrain-rmspe:0.999991\teval-rmspe:0.99999\n",
      "[2]\ttrain-rmse:11.0654\teval-rmse:11.0669\ttrain-rmspe:0.999985\teval-rmspe:0.999985\n",
      "[3]\ttrain-rmse:10.7337\teval-rmse:10.7351\ttrain-rmspe:0.999978\teval-rmspe:0.999978\n",
      "[4]\ttrain-rmse:10.4124\teval-rmse:10.4138\ttrain-rmspe:0.999968\teval-rmspe:0.999968\n",
      "[5]\ttrain-rmse:10.1004\teval-rmse:10.1017\ttrain-rmspe:0.999955\teval-rmspe:0.999955\n",
      "[6]\ttrain-rmse:9.79804\teval-rmse:9.79936\ttrain-rmspe:0.999938\teval-rmspe:0.999938\n",
      "[7]\ttrain-rmse:9.5043\teval-rmse:9.50563\ttrain-rmspe:0.999916\teval-rmspe:0.999917\n",
      "[8]\ttrain-rmse:9.21952\teval-rmse:9.22071\ttrain-rmspe:0.999888\teval-rmspe:0.999889\n",
      "[9]\ttrain-rmse:8.94312\teval-rmse:8.94439\ttrain-rmspe:0.999852\teval-rmspe:0.999853\n",
      "[10]\ttrain-rmse:8.67555\teval-rmse:8.6768\ttrain-rmspe:0.999806\teval-rmspe:0.999807\n",
      "[11]\ttrain-rmse:8.41556\teval-rmse:8.41684\ttrain-rmspe:0.999749\teval-rmspe:0.99975\n",
      "[12]\ttrain-rmse:8.1634\teval-rmse:8.16455\ttrain-rmspe:0.999678\teval-rmspe:0.999678\n",
      "[13]\ttrain-rmse:7.91891\teval-rmse:7.92002\ttrain-rmspe:0.999589\teval-rmspe:0.99959\n",
      "[14]\ttrain-rmse:7.68218\teval-rmse:7.68326\ttrain-rmspe:0.999478\teval-rmspe:0.99948\n",
      "[15]\ttrain-rmse:7.45198\teval-rmse:7.45303\ttrain-rmspe:0.999346\teval-rmspe:0.999347\n",
      "[16]\ttrain-rmse:7.22872\teval-rmse:7.22972\ttrain-rmspe:0.999185\teval-rmspe:0.999187\n",
      "[17]\ttrain-rmse:7.0121\teval-rmse:7.01311\ttrain-rmspe:0.998992\teval-rmspe:0.998994\n",
      "[18]\ttrain-rmse:6.80223\teval-rmse:6.80319\ttrain-rmspe:0.99876\teval-rmspe:0.998762\n",
      "[19]\ttrain-rmse:6.59842\teval-rmse:6.59941\ttrain-rmspe:0.998485\teval-rmspe:0.998487\n",
      "[20]\ttrain-rmse:6.40084\teval-rmse:6.40175\ttrain-rmspe:0.99816\teval-rmspe:0.998163\n",
      "[21]\ttrain-rmse:6.20914\teval-rmse:6.21004\ttrain-rmspe:0.997779\teval-rmspe:0.997782\n",
      "[22]\ttrain-rmse:6.02317\teval-rmse:6.02402\ttrain-rmspe:0.997334\teval-rmspe:0.997338\n",
      "[23]\ttrain-rmse:5.8428\teval-rmse:5.84364\ttrain-rmspe:0.996817\teval-rmspe:0.996821\n",
      "[24]\ttrain-rmse:5.66816\teval-rmse:5.66899\ttrain-rmspe:0.996213\teval-rmspe:0.996218\n",
      "[25]\ttrain-rmse:5.49846\teval-rmse:5.49925\ttrain-rmspe:0.995526\teval-rmspe:0.995532\n",
      "[26]\ttrain-rmse:5.33406\teval-rmse:5.33479\ttrain-rmspe:0.994736\teval-rmspe:0.994742\n",
      "[27]\ttrain-rmse:5.17452\teval-rmse:5.17527\ttrain-rmspe:0.993838\teval-rmspe:0.993845\n",
      "[28]\ttrain-rmse:5.01964\teval-rmse:5.02036\ttrain-rmspe:0.992826\teval-rmspe:0.992833\n",
      "[29]\ttrain-rmse:4.86942\teval-rmse:4.87011\ttrain-rmspe:0.991685\teval-rmspe:0.991694\n"
     ]
    }
   ],
   "source": [
    "rossman = Rossman()\n",
    "rossman.training(PATH_TRAIN,PATH_STORE,PATH_STORE_MODIFIED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acb2cbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhnaj\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "C:\\Users\\mhnaj\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:98: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:41] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSPE:  11.638607740005611\n"
     ]
    }
   ],
   "source": [
    "rossman.testing(PATH_TEST,PATH_STORE_MODIFIED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ff42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647e3c5c",
   "metadata": {},
   "source": [
    "# predicting Rossman sale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d292e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  OneHotEncoder,LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fcb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bb2e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhnaj\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3166: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "store = pd.read_csv(\"data/store.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd87fac",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595ed796",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637774 entries, 0 to 637773\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           637774 non-null  object \n",
      " 1   Store          618473 non-null  float64\n",
      " 2   DayOfWeek      618757 non-null  float64\n",
      " 3   Sales          618747 non-null  float64\n",
      " 4   Customers      618683 non-null  float64\n",
      " 5   Open           618588 non-null  float64\n",
      " 6   Promo          618580 non-null  float64\n",
      " 7   StateHoliday   618520 non-null  object \n",
      " 8   SchoolHoliday  618437 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 43.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41066a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Store                      1115 non-null   int64  \n",
      " 1   StoreType                  1115 non-null   object \n",
      " 2   Assortment                 1115 non-null   object \n",
      " 3   CompetitionDistance        1112 non-null   float64\n",
      " 4   CompetitionOpenSinceMonth  761 non-null    float64\n",
      " 5   CompetitionOpenSinceYear   761 non-null    float64\n",
      " 6   Promo2                     1115 non-null   int64  \n",
      " 7   Promo2SinceWeek            571 non-null    float64\n",
      " 8   Promo2SinceYear            571 non-null    float64\n",
      " 9   PromoInterval              571 non-null    object \n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "store.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa44c0b",
   "metadata": {},
   "source": [
    "### Missing value in Store.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c1c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef562cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Store                      1115 non-null   int64  \n",
      " 1   StoreType                  1115 non-null   object \n",
      " 2   Assortment                 1115 non-null   object \n",
      " 3   CompetitionDistance        1115 non-null   float64\n",
      " 4   CompetitionOpenSinceMonth  1115 non-null   float64\n",
      " 5   CompetitionOpenSinceYear   1115 non-null   float64\n",
      " 6   Promo2                     1115 non-null   int64  \n",
      " 7   Promo2SinceWeek            1115 non-null   float64\n",
      " 8   Promo2SinceYear            1115 non-null   float64\n",
      " 9   PromoInterval              1115 non-null   object \n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "def fillna_mean(df,columns):\n",
    "    for col in columns:\n",
    "        mean_value = int(df[col].mean())\n",
    "        df.loc[:,col].fillna(value=mean_value,inplace=True)\n",
    "    return df\n",
    "\n",
    "def fillna_most(df,columns):\n",
    "    for col in columns:\n",
    "        most_value = df[col].value_counts().idxmax()\n",
    "        df.loc[:,col].fillna(value=most_value,inplace=True)\n",
    "    return df\n",
    "columns_mean = ['CompetitionOpenSinceMonth',\n",
    "                'CompetitionOpenSinceYear',\n",
    "                'CompetitionDistance',\n",
    "                'Promo2SinceWeek',\n",
    "                'Promo2SinceYear'\n",
    "                 ] \n",
    "\n",
    "store = fillna_mean(store,columns_mean)\n",
    "\n",
    "columns_most = ['PromoInterval']\n",
    "stor = fillna_most(store,columns_most)\n",
    "\n",
    "\n",
    "store.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafdd7e",
   "metadata": {},
   "source": [
    "Drop rows that has no sales (zero or null value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442b5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['Sales'],inplace=True)\n",
    "#train.drop(columns=['Customers'],inplace=True)\n",
    "train.dropna(subset=['Store'],inplace=True) \n",
    "\n",
    "train= train[train['Sales']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e8f08",
   "metadata": {},
   "source": [
    "### Missing value in train.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb087f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497376 entries, 27 to 637773\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   Date           497376 non-null  datetime64[ns]\n",
      " 1   Store          497376 non-null  float64       \n",
      " 2   DayOfWeek      497376 non-null  float64       \n",
      " 3   Sales          497376 non-null  float64       \n",
      " 4   Customers      497376 non-null  float64       \n",
      " 5   Open           482366 non-null  float64       \n",
      " 6   Promo          497376 non-null  float64       \n",
      " 7   StateHoliday   497376 non-null  object        \n",
      " 8   SchoolHoliday  497376 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), object(1)\n",
      "memory usage: 37.9+ MB\n"
     ]
    }
   ],
   "source": [
    "columns_mean = ['DayOfWeek','Customers']\n",
    "train = fillna_mean(train,columns_mean)\n",
    "\n",
    "columns_most = ['Promo','SchoolHoliday','StateHoliday']\n",
    "train = fillna_most(train,columns_most)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc0fa1",
   "metadata": {},
   "source": [
    "Merge 'train' and 'store' together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "336e44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.merge(train,store, on='Store', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec890c52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497376 entries, 0 to 497375\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   Date                       497376 non-null  datetime64[ns]\n",
      " 1   Store                      497376 non-null  float64       \n",
      " 2   DayOfWeek                  497376 non-null  float64       \n",
      " 3   Sales                      497376 non-null  float64       \n",
      " 4   Customers                  497376 non-null  float64       \n",
      " 5   Open                       482366 non-null  float64       \n",
      " 6   Promo                      497376 non-null  float64       \n",
      " 7   StateHoliday               497376 non-null  object        \n",
      " 8   SchoolHoliday              497376 non-null  float64       \n",
      " 9   StoreType                  497376 non-null  object        \n",
      " 10  Assortment                 497376 non-null  object        \n",
      " 11  CompetitionDistance        497376 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  497376 non-null  float64       \n",
      " 13  CompetitionOpenSinceYear   497376 non-null  float64       \n",
      " 14  Promo2                     497376 non-null  int64         \n",
      " 15  Promo2SinceWeek            497376 non-null  float64       \n",
      " 16  Promo2SinceYear            497376 non-null  float64       \n",
      " 17  PromoInterval              497376 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(4)\n",
      "memory usage: 72.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d8c7b",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98dd2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    482366\n",
       "Name: Open, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full['Open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcc3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_full.drop(columns=['Open'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb29a1e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      445761\n",
       "0.0     51088\n",
       "a         401\n",
       "b          91\n",
       "c          35\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full['StateHoliday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd8580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full.loc[train_full['StateHoliday']==0,'StateHoliday']='0'\n",
    "train_full.loc[train_full['StateHoliday']=='0','StateHoliday']='0'\n",
    "\n",
    "train_full['StateHoliday'] = LabelEncoder().fit_transform(train_full['StateHoliday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d949f1e",
   "metadata": {},
   "source": [
    "### Define new feutures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ded12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full['CompetitionOpen'] = 12*(train_full.loc[:,'Date'].dt.year.max()-train_full.loc[:,'CompetitionOpenSinceYear'])-train_full.loc[:,'CompetitionOpenSinceMonth']    \n",
    "train_full['Promo2Open'] = 52*(train_full.loc[:,'Date'].dt.year.max()-train_full.loc[:,'Promo2SinceYear'])-train_full.loc[:,'Promo2SinceWeek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc51c32",
   "metadata": {},
   "source": [
    "#### Customer per Store per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c72c4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutomer_store = train_full.groupby('Store').agg(cust_st=('Customers','mean'))\n",
    "open_store = train_full.groupby('Store').agg(open_st=('Open','count'))\n",
    "#customer_day_store = (cutomer_store / open_store)\n",
    "#cutomer_store\n",
    "#train_full = pd.merge(train_full, customer_day_store, how='left', on=['Store'])\n",
    "#train_full['CustomersPerDay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5857a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_st</th>\n",
       "      <th>open_st</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_st  open_st\n",
       "Store                   \n",
       "1.0         NaN      NaN\n",
       "2.0         NaN      NaN\n",
       "3.0         NaN      NaN\n",
       "4.0         NaN      NaN\n",
       "5.0         NaN      NaN\n",
       "...         ...      ...\n",
       "1111.0      NaN      NaN\n",
       "1112.0      NaN      NaN\n",
       "1113.0      NaN      NaN\n",
       "1114.0      NaN      NaN\n",
       "1115.0      NaN      NaN\n",
       "\n",
       "[1115 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cutomer_store / open_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1045aa63",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reset_index() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-237274f995b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcustomer_day_store\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcutomer_store\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mopen_store\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustomer_day_store\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'CustomersPerDay'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Store'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: reset_index() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "customer_day_store = (cutomer_store / open_store)\n",
    "train_full = pd.merge(train_full, customer_day_store.reset_index(name='CustomersPerDay'), how='left', on=['Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f164d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_day_store = (cutomer_store / open_store)\n",
    "\n",
    "#train_full = pd.merge(train_full, customer_day_store, how='left', on=['Store'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb28bb",
   "metadata": {},
   "source": [
    "#### Promo yesterday and tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73291f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_full['PromoTomorrow'] = train_full['Promo'].shift(-1)\n",
    "#train_full['PromoYesterday'] = train_full['Promo'].shift(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333a147",
   "metadata": {},
   "source": [
    "#### Holiday last week , this week and next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae077d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def holidays_week(df,start,end,start_past=False):\n",
    "    holidays = []\n",
    "    holidays_index = []\n",
    "    for index,value in df.groupby('Date').sum().iterrows():\n",
    "        first = index + datetime.timedelta(days=start)\n",
    "        if start_past:\n",
    "            first = index - datetime.timedelta(days=start)\n",
    "        last =  index + datetime.timedelta(days=end)\n",
    "        school_holidays = sum((df.groupby('Date').sum()[first:last])['SchoolHoliday'])\n",
    "        state_holidays = sum((df.groupby('Date').sum()[first:last])['StateHoliday'])\n",
    "        holidays.append(school_holidays+state_holidays)\n",
    "        holidays_index.append(index)\n",
    "    return holidays,holidays_index\n",
    "\n",
    "holidays_last_week,holidays_last_index=holidays_week(train_full,7,1,start_past=True)\n",
    "holidays_this_week,holidays_this_index=holidays_week(train_full,0,7)\n",
    "holidays_next_week,holidays_next_index=holidays_week(train_full,7,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11617bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'HolidaysLastWeek':holidays_last_week, 'Date': holidays_last_index})\n",
    "train_full = pd.merge(train_full, temp_df, on=['Date'])\n",
    "\n",
    "temp_df = pd.DataFrame({'HolidaysThisWeek':holidays_this_week, 'Date': holidays_this_index})\n",
    "train_full = pd.merge(train_full, temp_df, on=['Date'])\n",
    "\n",
    "temp_df = pd.DataFrame({'HolidaysNextWeek':holidays_next_week, 'Date': holidays_next_index})\n",
    "train_full = pd.merge(train_full, temp_df, on=['Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1888b3",
   "metadata": {},
   "source": [
    "### Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "973042a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df,columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df = pd.get_dummies(df, columns = [col])\n",
    "    return df\n",
    "\n",
    "train_full = get_dummies(train_full,['StoreType','Assortment','PromoInterval'])\n",
    "\n",
    "freq = train_full.groupby('Store').size()/len(train_full)\n",
    "train_full.loc[:,'Store_freq'] = train_full.loc[:,'Store'].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0027413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>...</th>\n",
       "      <th>StoreType_b</th>\n",
       "      <th>StoreType_c</th>\n",
       "      <th>StoreType_d</th>\n",
       "      <th>Assortment_a</th>\n",
       "      <th>Assortment_b</th>\n",
       "      <th>Assortment_c</th>\n",
       "      <th>PromoInterval_Feb,May,Aug,Nov</th>\n",
       "      <th>PromoInterval_Jan,Apr,Jul,Oct</th>\n",
       "      <th>PromoInterval_Mar,Jun,Sept,Dec</th>\n",
       "      <th>Store_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>353.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>335.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>494.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3113.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  DayOfWeek   Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "0 2013-01-01  353.0        2.0  3139.0      820.0   1.0    0.0             1   \n",
       "1 2013-01-01  335.0        2.0  2401.0      482.0   1.0    0.0             1   \n",
       "2 2013-01-01  512.0        2.0  2646.0      625.0   1.0    0.0             1   \n",
       "3 2013-01-01  494.0        2.0  3113.0      527.0   1.0    0.0             1   \n",
       "4 2013-01-01  530.0        2.0  2907.0      532.0   1.0    0.0             1   \n",
       "\n",
       "   SchoolHoliday  CompetitionDistance  ...  StoreType_b  StoreType_c  \\\n",
       "0            1.0                900.0  ...            1            0   \n",
       "1            1.0                 90.0  ...            1            0   \n",
       "2            1.0                590.0  ...            1            0   \n",
       "3            1.0               1260.0  ...            1            0   \n",
       "4            1.0              18160.0  ...            0            0   \n",
       "\n",
       "   StoreType_d  Assortment_a  Assortment_b  Assortment_c  \\\n",
       "0            0             0             1             0   \n",
       "1            0             1             0             0   \n",
       "2            0             0             1             0   \n",
       "3            0             1             0             0   \n",
       "4            0             0             0             1   \n",
       "\n",
       "   PromoInterval_Feb,May,Aug,Nov  PromoInterval_Jan,Apr,Jul,Oct  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              0                              0   \n",
       "3                              0                              1   \n",
       "4                              0                              1   \n",
       "\n",
       "   PromoInterval_Mar,Jun,Sept,Dec  Store_freq  \n",
       "0                               0    0.001074  \n",
       "1                               0    0.001100  \n",
       "2                               1    0.000995  \n",
       "3                               0    0.001094  \n",
       "4                               0    0.001052  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df843910",
   "metadata": {},
   "source": [
    "### Split Data: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f560fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_full.drop(columns=['Sales','Date','Open','Customers','Store','CompetitionOpenSinceYear','CompetitionOpenSinceMonth','Promo2SinceYear','Promo2SinceWeek'])\n",
    "y = train_full['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98336212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5188216",
   "metadata": {},
   "source": [
    "### Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a76de0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a764ac47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4e034ee35acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m             )\n\u001b[0;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[1;32m--> 304\u001b[1;33m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 646\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n\u001b[1;32m--> 100\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    101\u001b[0m             )\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "rf = RandomForestRegressor(max_depth=30)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4df55d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rmspe = metric(predictions,y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7845d694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.25040278702535"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 50, 80],\n",
    "    'max_features': [3, 5,7],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_estimator_\n",
    "best_grid = grid_search.best_estimator_\n",
    "predictions = best_grid.predict(X_test)\n",
    "\n",
    "rf_rmspe = metric(predictions,y_test.to_numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7f635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
